# å…ˆçœ‹æ•ˆæœ DS-slow motion

å·¦è¾¹ä¸ºåŸè§†é¢‘ï¼Œå³è¾¹ä¸ºå¯¹ç¬¬ä¸€ä¸ªè·ƒèµ·åŠ¨ä½œè¿›è¡Œslow motionçš„è§†é¢‘ï¼ˆåªå¯¹è§†é¢‘ä¸­ç²¾å½©æ—¶åˆ»åšslow motionï¼Œæ„Ÿè§‰èƒ½çœ‹å‡ºæ•ˆæœï¼‰

PS:è§†é¢‘æ¥è‡ªå¤®è§†æ–°é—»Bç«™

[![Bilibili Video](https://raw.github.com/GabLeRoux/WebMole/master/ressources/WebMole_Youtube_Video.png)](//player.bilibili.com/player.html?aid=716545006&bvid=BV18X4y1w7qx&cid=366949522&page=1)



# 1 èƒŒæ™¯ä»‹ç»

## 1.1 ä½¿ç”¨è¯´æ˜ï¼š
è‹¥åªæ˜¯æƒ³æŠŠè§†é¢‘å®ç°æ…¢åŠ¨ä½œslow motionæ•ˆæœï¼Œç›´æ¥è·³åˆ°â€œ3è§†é¢‘æ…¢åŠ¨ä½œâ€ ï¼Œæ ¹æ®è¯´æ˜è®¾ç½®å‚æ•°å³å¯ã€‚è‹¥è¦äº†è§£è¿‡ç¨‹ï¼Œå¯ç»§ç»­é˜…è¯»ã€‚

## 1.2 DS -- Deepshopï¼š
1.åœ¨å›¾åƒç¼–è¾‘ä¸­æœ‰å¤§åé¼é¼çš„photoshopä½œä¸ºå›¾åƒå¤„ç†å·¥å…·ï¼Œé‚£åœ¨è¿™é‡Œæˆ‘æ‰“ç®—ä¹Ÿå¼„ä¸ªDeepshopä½œä¸ºå›¾åƒå¤„ç†çš„æ·±åº¦å·¥å…·ç®±ï¼Œå¼€ç®±å³ç”¨ã€‚

2.åç»­ä¹Ÿä¼šé™†ç»­æ•´ç†å…¶ä»–å·¥å…·ï¼Œè¿™æ¬¡æ•´ç†äº†è§†é¢‘æ…¢åŠ¨ä½œå·¥å…·çš„

3.è‡³2021å¹´6æœˆï¼Œè¿™ä¸ªæ¨¡å‹åŸºäºmsgnetè¿ç§»è®­ç»ƒï¼Œæ•ˆæœç¦»ä»¥å‡ä¹±çœŸè¿˜æœ‰ç‚¹è·ç¦»ï¼Œæ•ˆæœè¿˜å¯ä»¥ç»§ç»­ä¼˜åŒ–ï¼Œstylepro_artisticé‚£ä¸ªè¿ç§»å¯èƒ½æ•ˆæœæ›´å¥½ï¼Œå¯æƒœæš‚æ—¶æ²¡æ‰¾åˆ°é‚£ä¸ªå¯ä»¥è¿ç§»çš„ï¼Œæœ‰æ—¶é—´çœ‹ä»å¤´è®­ç»ƒä¸€ä¸ªã€‚

## 1.3 æ…¢åŠ¨ä½œslow motion
1.éšç€æ‰‹æœºæ‘„åƒå¤´å¸§ç‡åŠ¨ä¸åŠ¨å°±120fpsï¼Œ60fpsï¼Œç°åœ¨æ‹æ…¢åŠ¨ä½œä¹Ÿå¾ˆç®€å•äº†ã€‚ä½†è‹¥åŸè§†é¢‘åªæœ‰25fpsï¼Œ30fpsçš„è¦å˜æˆæ…¢åŠ¨ä½œè§†é¢‘è¿˜æ˜¯å¯ä»¥ç”¨DLçš„æ–¹æ³•

2.å°±æ˜¯åˆ©ç”¨ppganï¼ˆPaddleGANä¸­çš„DAINæ¨¡å‹ï¼ŒåŸæœ¬å°±æ˜¯æ’å¸§çš„DLç®—æ³•ï¼Œåœ¨è¿™é‡Œç”¨DAINæ’äº†å¸§åï¼Œä¿æŒåŸè§†é¢‘å¸§ç‡ä¸å¢åŠ å¸§ç‡ï¼Œåªå¢åŠ äº†æ€»å¸§æ•°ã€‚ç›¸å½“äºå¢åŠ è§†é¢‘é•¿åº¦ï¼Œä½†è§†é¢‘å†…å®¹çš„çœŸå®æ—¶é—´é•¿åº¦æ˜¯ä¸å˜çš„ï¼Œæ‰€ä»¥ç›¸å½“äºå®ç°æ…¢åŠ¨ä½œï¼Œå¤„ç†çš„é‚£æ®µè§†é¢‘å˜æˆæ…¢åŠ¨ä½œäº†ã€‚

3.è¿™é‡Œåªæ˜¯å°å°ä¿®æ”¹ï¼Œæ–¹ä¾¿è¿›è¡Œä½¿ç”¨è€Œå·²ï¼ŒæŠ€æœ¯æºè‡ªDAINä¸PaddlePaddle

# 2 DAINä»‹ç»


## 2.1 æ·±åº¦å­¦ä¹ æ’å¸§æ¨¡å‹

å½“å‰æœ‰ä¸å°‘æ’å¸§çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè‹±ä¼Ÿè¾¾çš„Super slomoï¼Œä¸Šæµ·äº¤å¤§çš„DAINã€‚éƒ½æ˜¯ä¸ºè§†é¢‘æ’å¸§ï¼Œä½¿è§†é¢‘çœ‹èµ·æ¥æ›´ä¸æ»‘ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æŠŠæ’çš„å¸§ï¼Œä¸ç”¨æ¥æå‡å¸§ç‡ï¼Œè€Œæ˜¯å»¶é•¿æ•´ä¸ªè§†é¢‘é•¿åº¦ï¼Œå½¢æˆæ…¢åŠ¨ä½œslow motionæ•ˆæœã€‚

![](https://ai-studio-static-online.cdn.bcebos.com/43ae52cfbe9e478f9b92eea72273fd7e491b267971dd4175a978de25b6bd1643)


## 2.2 æ·±åº¦æ„ŸçŸ¥è§†é¢‘å¸§æ’å€¼ DAIN

DAINçš„å…¨ç§°æ˜¯Depth-Aware Video Frame Interpolationï¼Œ2019å¹´çš„CVPR.å®˜æ–¹çš„github [https://github.com/baowenbo/DAIN](https://github.com/baowenbo/DAIN)

![](https://ai-studio-static-online.cdn.bcebos.com/c6ae825daec94f0cb69ea223a7e6610737457cb23fb44887af4234cc198a00a3)


â€”â€” ç»™å®šä¸¤ä¸ªæ—¶åˆ»çš„è¾“å…¥å¸§ï¼Œå…ˆä¼°è®¡å…‰æµå’Œæ·±åº¦å›¾ï¼Œç„¶åä½¿ç”¨å»ºè®®çš„æ·±åº¦æ„ŸçŸ¥æµæŠ•å½±å±‚ç”Ÿæˆä¸­é—´æµã€‚ç„¶åï¼Œæ¨¡å‹åŸºäºå…‰æµå’Œå±€éƒ¨æ’å€¼å†…æ ¸å¯¹è¾“å…¥å¸§ã€æ·±åº¦å›¾å’Œä¸Šä¸‹æ–‡ç‰¹å¾è¿›è¡Œæ‰­æ›²ï¼Œåˆæˆè¾“å‡ºå¸§ã€‚è¿™ç§æ¨¡å‹ç´§å‡‘ã€é«˜æ•ˆä¸”å®Œå…¨å¯å¾®åˆ†ã€‚

å‚è€ƒè‡ª [https://zhuanlan.zhihu.com/p/149395616](https://zhuanlan.zhihu.com/p/149395616)

![](https://ai-studio-static-online.cdn.bcebos.com/e4aa8d58bcde4c2486b8bc7f8a88fe6c47ab56d17ffa443fa31bb3143ff4b30e)

â€”â€” å¹¶ä¸”ï¼Œé¡¹ç›®å¹¶æ²¡æœ‰é¢„è®­ç»ƒçš„åˆ†ç±»ç½‘ç»œï¼Œè€Œæ˜¯è‡ªå·±è®­ç»ƒäº†ä¸€ä¸ªå†…å®¹è¾“å‡ºç½‘ç»œæ¥è·å–é«˜ç»´ç‰¹å¾ï¼Œæ¥ç»™è§†é¢‘æ’å€¼ã€‚

## 2.3 ä¸Šæ‰‹æ’å¸§ç†

### 2.3.1ç”¨PaddleGANçš„DAINæ’å¸§:

ç›´æ¥è°ƒç”¨å°è£…å¥½çš„ç±»ï¼š


```python
## éœ€è¦æ’å¸§çš„è®¾ç½®True
baseUse=False
## æŒ‡å®šè¦æ’å¸§çš„è§†é¢‘æ–‡ä»¶
path='/home/aistudio/huaxue.mp4'
#
if baseUse:
    !pip install -q ppgan
    import paddle
    from ppgan.apps import DAINPredictor
    ##éœ€æ³¨æ„ç”¨é™æ€å›¾
    paddle.enable_static()
    dain=DAINPredictor(output='output',
                    weight_path=None,
                    time_step=0.5,
                    use_gpu=True,
                    remove_duplicates=False)
    dain.run(path)
```

### 2.3.2 ç”¨åˆ«çš„æ•´åˆçš„DAIN æ’å¸§

è‹¥è§‰å¾—æ”¹ä¸€è¡Œä»£ç ä¹Ÿç´¯ï¼Œæƒ³ç›´æ¥ç”¨ï¼Œå¯æ‰¾å·²æœ‰çš„ç½‘é¡µ[http://distinctai.net/fps](http://http://distinctai.net/fps) ï¼Œé™åˆ¶å°±æ˜¯ï¼šå…è´¹è¯•ç”¨æœ€å¤§ä¸è¶…è¿‡10Mï¼Œæ”¯æŒMP4ã€aviã€rmvbç­‰å¤šç§æ ¼å¼ï¼Œä¸‰æ¬¡å…è´¹

# 3 è§†é¢‘æ…¢åŠ¨ä½œ

## 3.1 å®‰è£…PaddleGAN

æˆ‘ç”¨æœ€æ‡’æ–¹æ³•ç›´æ¥pipå®‰è£…ï¼Œæœ‰éœ€è¦çš„ä¹Ÿå¯ä»¥gitåå®‰è£…


```python
!pip install -q ppgan
```

## 3.2 åˆ›å»ºæ…¢åŠ¨ä½œç±»

1.åœ¨githubä¸Šè¿½è¸ªDAINçš„ä»£ç ï¼Œåœ¨ ppgan.appsä¸‹é¢çš„dainç±»æ‹·è´å‡ºæ¥ï¼Œè¿›è¡Œä¿®æ”¹ï¼ˆå› æ”¹åŠ¨ä¸å°‘å°±æ²¡æœ‰ç»§æ‰¿DAINäº†ï¼‰

2.ä¸»è¦ä¿®æ”¹éƒ¨åˆ†æ˜¯frameåˆæˆè§†é¢‘æ—¶ï¼ŒåŠ combine_framesæ–¹æ³•ã€‚ä¸»è¦æ”¹å›¾ç‰‡çš„åå­—ï¼Œç„¶åæ”¾åˆ°output/DAIN/frames-combinedä¸­

PSï¼šppganè¿™é‡Œç”¨çš„æ˜¯ffmpegç”Ÿæˆè§†é¢‘ï¼ŒæŒ‡å®šå›¾ç‰‡æ–‡ä»¶å¤¹æ‰€åœ¨è·¯å¾„æ¥ç”Ÿæˆã€‚è¿™é‡Œæ³¨æ„å›¾ç‰‡æ–‡ä»¶åè¦æ±‚ä»000.png(0å¼€å§‹ï¼‰ä¸€ç›´è¿ç»­é¡ºåºé€’å¢ï¼ˆ0001.png,0002.pngç­‰ï¼‰ï¼ï¼è¿™é‡Œå‘äº†ä¸å°‘æ—¶é—´


```python
import os
import cv2
import glob
import shutil
import numpy as np
from tqdm import tqdm
from imageio import imread, imsave

import paddle
from ppgan.utils.download import get_path_from_url
from ppgan.utils.video import video2frames, frames2video

from ppgan.apps.base_predictor import BasePredictor
paddle.enable_static()
DAIN_WEIGHT_URL = 'https://paddlegan.bj.bcebos.com/applications/DAIN_weight.tar'


class DAINSlowMotion(BasePredictor):
    def __init__(self,
                 output='output',
                 weight_path=None,
                 use_gpu=True,
                 remove_duplicates=False):
        self.output_path = os.path.join(output, 'DAIN')
        if weight_path is None:
            weight_path = get_path_from_url(DAIN_WEIGHT_URL)

        self.weight_path = weight_path
        #self.time_step = time_step
        self.key_frame_thread = 0
        self.remove_duplicates = remove_duplicates

        self.build_inference_model()

    def run(self, video_path,slow_rate=0.5,frameIndex=[],interpolateIndex=[]):
        self.time_step=slow_rate
        if len(frameIndex)!=2:
            self.frame_start=0
            self.frame_end=-1
        else:
            self.frame_start=frameIndex[0]
            self.frame_end=frameIndex[1]
        if len(interpolateIndex)!=2:
            self.interpolate_start=0
            self.interpolate_end=-1
        else:
            self.interpolate_start=interpolateIndex[0]
            self.interpolate_end=interpolateIndex[1]
        frame_path_input = os.path.join(self.output_path, 'frames-input')
        frame_path_interpolated = os.path.join(self.output_path,
                                               'frames-interpolated')
        frame_path_combined = os.path.join(self.output_path, 'frames-combined')
        video_path_output = os.path.join(self.output_path, 'videos-output')

        if not os.path.exists(self.output_path):
            os.makedirs(self.output_path)
        if not os.path.exists(frame_path_input):
            os.makedirs(frame_path_input)
        if not os.path.exists(frame_path_interpolated):
            os.makedirs(frame_path_interpolated)
        if not os.path.exists(frame_path_combined):
            os.makedirs(frame_path_combined)
        if not os.path.exists(video_path_output):
            os.makedirs(video_path_output)

        timestep = self.time_step
        num_frames = int(1.0 / timestep) - 1

        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        print("Old fps (frame rate): ", fps)

        times_interp = int(1.0 / timestep)
        r2 = str(int(fps) * times_interp)
        print("New fps (frame rate): ", fps)

        out_path = video2frames(video_path, frame_path_input)

        vidname = os.path.basename(video_path).split('.')[0]

        frames = sorted(glob.glob(os.path.join(out_path, '*.png')))
        frames=frames[self.frame_start:self.frame_end]
        #print('frames',frames)
        # if self.remove_duplicates:
        #     frames = self.remove_duplicate_frames(out_path)

        img = imread(frames[0])

        int_width = img.shape[1]
        int_height = img.shape[0]
        channel = img.shape[2]
        if not channel == 3:
            return

        if int_width != ((int_width >> 7) << 7):
            int_width_pad = (((int_width >> 7) + 1) << 7)  # more than necessary
            padding_left = int((int_width_pad - int_width) / 2)
            padding_right = int_width_pad - int_width - padding_left
        else:
            int_width_pad = int_width
            padding_left = 32
            padding_right = 32

        if int_height != ((int_height >> 7) << 7):
            int_height_pad = (
                ((int_height >> 7) + 1) << 7)  # more than necessary
            padding_top = int((int_height_pad - int_height) / 2)
            padding_bottom = int_height_pad - int_height - padding_top
        else:
            int_height_pad = int_height
            padding_top = 32
            padding_bottom = 32

        frame_num = len(frames)

        if not os.path.exists(os.path.join(frame_path_interpolated, vidname)):
            os.makedirs(os.path.join(frame_path_interpolated, vidname))
        if not os.path.exists(os.path.join(frame_path_combined, vidname)):
            os.makedirs(os.path.join(frame_path_combined, vidname))

        for i in tqdm(range(frame_num - 1)):
            if i < self.interpolate_start or (i>self.interpolate_end and self.interpolate_end>0):continue

            first = frames[i]
            second = frames[i + 1]
            first_index = int(first.split(os.sep)[-1].split('.')[-2])
            second_index = int(second.split(os.sep)[-1].split('.')[-2])

            img_first = imread(first)
            img_second = imread(second)
            '''--------------Frame change test------------------------'''
            #img_first_gray = np.dot(img_first[..., :3], [0.299, 0.587, 0.114])
            #img_second_gray = np.dot(img_second[..., :3], [0.299, 0.587, 0.114])

            #img_first_gray = img_first_gray.flatten(order='C')
            #img_second_gray = img_second_gray.flatten(order='C')
            #corr = np.corrcoef(img_first_gray, img_second_gray)[0, 1]
            #key_frame = False
            #if corr < self.key_frame_thread:
            #    key_frame = True
            '''-------------------------------------------------------'''

            X0 = img_first.astype('float32').transpose((2, 0, 1)) / 255
            X1 = img_second.astype('float32').transpose((2, 0, 1)) / 255

            assert (X0.shape[1] == X1.shape[1])
            assert (X0.shape[2] == X1.shape[2])

            X0 = np.pad(X0, ((0,0), (padding_top, padding_bottom), \
                (padding_left, padding_right)), mode='edge')
            X1 = np.pad(X1, ((0,0), (padding_top, padding_bottom), \
                (padding_left, padding_right)), mode='edge')

            X0 = np.expand_dims(X0, axis=0)
            X1 = np.expand_dims(X1, axis=0)

            X0 = np.expand_dims(X0, axis=0)
            X1 = np.expand_dims(X1, axis=0)

            X = np.concatenate((X0, X1), axis=0)

            o = self.base_forward(X)

            y_ = o[0]

            y_ = [
                np.transpose(
                    255.0 * item.clip(
                        0, 1.0)[0, :, padding_top:padding_top + int_height,
                                padding_left:padding_left + int_width],
                    (1, 2, 0)) for item in y_
            ]
            if self.remove_duplicates:
                num_frames = times_interp * (second_index - first_index) - 1
                time_offsets = [
                    kk * timestep for kk in range(1, 1 + num_frames, 1)
                ]
                start = times_interp * first_index + 1
                for item, time_offset in zip(y_, time_offsets):
                    out_dir = os.path.join(frame_path_interpolated, vidname,
                                           "{:08d}.png".format(start))
                    imsave(out_dir, np.round(item).astype(np.uint8))
                    start = start + 1

            else:
                time_offsets = [
                    kk * timestep for kk in range(1, 1 + num_frames, 1)
                ]

                count = 1
                for item, time_offset in zip(y_, time_offsets):
                    out_dir = os.path.join(
                        frame_path_interpolated, vidname,
                        "{:08d}{:01d}.png".format(self.frame_start+i, count))
                    count = count + 1
                    imsave(out_dir, np.round(item).astype(np.uint8))

        input_dir = os.path.join(frame_path_input, vidname)
        interpolated_dir = os.path.join(frame_path_interpolated, vidname)
        combined_dir = os.path.join(frame_path_combined, vidname)
        ##kevin
        ##if self.remove_duplicates:
        ##    self.combine_frames_with_rm(input_dir, interpolated_dir,
        ##                                combined_dir, times_interp)

       ## else:
        num_frames = int(1.0 / timestep) - 1
        self.combine_frames(frames, interpolated_dir, combined_dir,
                            num_frames)

        frame_pattern_combined = os.path.join(frame_path_combined, vidname,
                                              '%08d.png')
        #frame_pattern_combined = sorted(glob.glob(os.path.join(frame_path_combined,vidname, '*.png')))
        #print('frame_pattern_combined',frame_pattern_combined)
        video_pattern_output = os.path.join(video_path_output, vidname + '.mp4')
        if os.path.exists(video_pattern_output):
            os.remove(video_pattern_output)
        #kevin
        frames2video(frame_pattern_combined, video_pattern_output,str(int (fps)))
        #
        return frame_pattern_combined, video_pattern_output

    def combine_frames(self, frames, interpolated, combined, num_frames):
        frames1 = frames
        frames2 = sorted(glob.glob(os.path.join(interpolated, '*.png')))
        num1 = len(frames1)
        num2 = len(frames2)

        for i in range(num1):
            
            src = frames1[i]
            imgname = int(src.split(os.sep)[-1].split('.')[-2])
            if imgname<=self.interpolate_start:
                 dst=os.path.join(combined,'{:08d}.png'.format(imgname-self.frame_start))
            elif imgname<=self.interpolate_end:
                dst=os.path.join(combined,'{:08d}.png'.format((imgname-self.interpolate_start)*num_frames+imgname-self.frame_start))
            else:
                dst=os.path.join(combined,'{:08d}.png'.format((self.interpolate_end-self.interpolate_start)*(num_frames+1) \
                +self.interpolate_start+(i-self.interpolate_end)-self.frame_start))
            # print('i,imgname',i,imgname)
            #assert i == imgname
            #dst = os.path.join(combined,
            #                   '{:08d}.png'.format(imgname * (num_frames + 1)))
            
            shutil.copy2(src, dst)
            #print('dst1',dst)
        for i in range(num2):
            try:
                
                imgname = src.split(os.sep)[-1]
                src = frames2[i ]
                #src2=src[-12:-4]+'_'
                dst = os.path.join(
                    combined,'{:08d}.png'.format((i+self.interpolate_start+1+i//num_frames)-self.frame_start))
                #print('dst2',dst)
                shutil.copy2(src, dst)
                    
                    
            except Exception as e:
                print(e)

    def combine_frames_with_rm(self, input, interpolated, combined,
                               times_interp):
        frames1 = sorted(glob.glob(os.path.join(input, '*.png')))
        frames2 = sorted(glob.glob(os.path.join(interpolated, '*.png')))
        num1 = len(frames1)
        num2 = len(frames2)

        for i in range(num1):
            src = frames1[i]
            index = int(src.split(os.sep)[-1].split('.')[-2])
            dst = os.path.join(combined,
                               '{:08d}.png'.format(times_interp * index))
            shutil.copy2(src, dst)

        for i in range(num2):
            src = frames2[i]
            imgname = src.split(os.sep)[-1]
            dst = os.path.join(combined, imgname)
            shutil.copy2(src, dst)

    def remove_duplicate_frames(self, paths):
        def dhash(image, hash_size=8):
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            resized = cv2.resize(gray, (hash_size + 1, hash_size))
            diff = resized[:, 1:] > resized[:, :-1]
            return sum([2**i for (i, v) in enumerate(diff.flatten()) if v])

        hashes = {}
        max_interp = 9
        image_paths = sorted(glob.glob(os.path.join(paths, '*.png')))
        for image_path in image_paths:
            image = cv2.imread(image_path)
            h = dhash(image)
            p = hashes.get(h, [])
            p.append(image_path)
            hashes[h] = p

        for (h, hashed_paths) in hashes.items():
            if len(hashed_paths) > 1:
                first_index = int(hashed_paths[0].split(
                    os.sep)[-1].split('.')[-2])
                last_index = int(hashed_paths[-1].split(
                    os.sep)[-1].split('.')[-2]) + 1
                gap = 2 * (last_index - first_index) - 1
                if gap > 2 * max_interp:
                    cut1 = len(hashed_paths) // 3
                    cut2 = cut1 * 2
                    for p in hashed_paths[1:cut1 - 1]:
                        os.remove(p)
                    for p in hashed_paths[cut1 + 1:cut2]:
                        os.remove(p)
                    for p in hashed_paths[cut2 + 1:]:
                        os.remove(p)
                if gap > max_interp:
                    mid = len(hashed_paths) // 2
                    for p in hashed_paths[1:mid - 1]:
                        os.remove(p)
                    for p in hashed_paths[mid + 1:]:
                        os.remove(p)
                else:
                    for p in hashed_paths[1:]:
                        os.remove(p)

        frames = sorted(glob.glob(os.path.join(paths, '*.png')))
        return frames
```

# 4æ¨¡å‹ä½¿ç”¨


```python
!rm -rf /home/aistudio/output/DAIN
#æ…¢åŠ¨ä½œé€Ÿç‡ï¼Œ0.25ç›¸å½“äº æ–°ç”Ÿæˆ3å¸§
slow_rate=0.25
# å¾…å¤„ç†è§†é¢‘è·¯å¾„
path='/home/aistudio/shijinsai.mp4'
## è£åˆ‡è§†é¢‘videoIndex=[a,b]ï¼Œåˆ°æ—¶å€™åªè¾“å‡ºè§†é¢‘çš„ç¬¬aå¸§åˆ°ç¬¬bå¸§ï¼Œæ•´ä¸ªè§†é¢‘åˆ™è®¾ç©ºæ•°ç»„[]
videoIndex=[]
## è£åˆ‡è§†é¢‘ï¼Œå…ˆæŠŠç¬¬å‡ å¸§åˆ°ç¬¬å‡ å¸§çš„è§†é¢‘åˆ‡å‡ºæ¥ï¼Œä¸åˆ‡å–è§†é¢‘åˆ™è®¾ç©ºæ•°ç»„[],è¿™é‡Œè¿˜æ˜¯åŸè§†é¢‘çš„å¸§æ•°
slowIndex=[120,150]
dain=DAINSlowMotion(output='output',
                 weight_path=None,
                 use_gpu=True,
                 remove_duplicates=False)
##è¾“å‡ºè§†é¢‘åœ¨ output/DAIN/videos-output
dain.run(path,slow_rate,videoIndex,slowIndex)
```

    [07/09 16:24:17] ppgan INFO: Found /home/aistudio/.cache/ppgan/DAIN_weight.tar
    [07/09 16:24:17] ppgan INFO: Decompressing /home/aistudio/.cache/ppgan/DAIN_weight.tar...


    2021-07-09 16:24:17,776-WARNING: The old way to load inference model is deprecated. model path: /home/aistudio/.cache/ppgan/DAIN_weight/model, params path: /home/aistudio/.cache/ppgan/DAIN_weight/params


    Old fps (frame rate):  25.0
    New fps (frame rate):  25.0


    
      0%|          | 0/356 [00:00<?, ?it/s][A
     34%|â–ˆâ–ˆâ–ˆâ–      | 121/356 [00:08<00:16, 14.55it/s][A
     34%|â–ˆâ–ˆâ–ˆâ–      | 122/356 [00:16<10:19,  2.65s/it][A
     35%|â–ˆâ–ˆâ–ˆâ–      | 123/356 [00:25<16:37,  4.28s/it][A
     35%|â–ˆâ–ˆâ–ˆâ–      | 124/356 [00:32<20:33,  5.32s/it][A
     35%|â–ˆâ–ˆâ–ˆâ–Œ      | 125/356 [00:40<23:05,  6.00s/it][A
     35%|â–ˆâ–ˆâ–ˆâ–Œ      | 126/356 [00:48<25:03,  6.54s/it][A
     36%|â–ˆâ–ˆâ–ˆâ–Œ      | 127/356 [00:55<25:32,  6.69s/it][A
     36%|â–ˆâ–ˆâ–ˆâ–Œ      | 128/356 [01:05<29:03,  7.65s/it][A
     36%|â–ˆâ–ˆâ–ˆâ–Œ      | 129/356 [01:10<26:28,  7.00s/it][A
     37%|â–ˆâ–ˆâ–ˆâ–‹      | 130/356 [01:17<26:01,  6.91s/it][A
     37%|â–ˆâ–ˆâ–ˆâ–‹      | 131/356 [01:24<26:06,  6.96s/it][A
     37%|â–ˆâ–ˆâ–ˆâ–‹      | 132/356 [01:32<26:45,  7.17s/it][A
     37%|â–ˆâ–ˆâ–ˆâ–‹      | 133/356 [01:40<27:55,  7.51s/it][A
     38%|â–ˆâ–ˆâ–ˆâ–Š      | 134/356 [01:49<29:11,  7.89s/it][A
     38%|â–ˆâ–ˆâ–ˆâ–Š      | 135/356 [01:57<29:48,  8.09s/it][A
     38%|â–ˆâ–ˆâ–ˆâ–Š      | 136/356 [02:06<30:23,  8.29s/it][A
     38%|â–ˆâ–ˆâ–ˆâ–Š      | 137/356 [02:15<30:41,  8.41s/it][A
     39%|â–ˆâ–ˆâ–ˆâ–‰      | 138/356 [02:23<31:03,  8.55s/it][A
     39%|â–ˆâ–ˆâ–ˆâ–‰      | 139/356 [02:32<31:01,  8.58s/it][A
     39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/356 [02:41<30:58,  8.60s/it][A
     40%|â–ˆâ–ˆâ–ˆâ–‰      | 141/356 [02:49<30:52,  8.61s/it][A
     40%|â–ˆâ–ˆâ–ˆâ–‰      | 142/356 [02:58<30:17,  8.49s/it][A
     40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 143/356 [03:06<29:57,  8.44s/it][A
     40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/356 [03:14<29:34,  8.37s/it][A
     41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 145/356 [03:22<29:16,  8.32s/it][A
     41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 146/356 [03:30<28:32,  8.15s/it][A
     41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147/356 [03:38<27:50,  7.99s/it][A
     42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/356 [03:45<27:06,  7.82s/it][A
     42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/356 [03:52<26:17,  7.62s/it][A
     42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/356 [03:59<25:40,  7.48s/it][A
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 356/356 [04:06<00:00,  1.44it/s][A





    ('output/DAIN/frames-combined/shijinsai/%08d.png',
     'output/DAIN/videos-output/shijinsai.mp4')



# 5 æ€»ç»“

## 5.1 æ•ˆæœ
ç”Ÿæˆçš„å¸§çš„æ•ˆæœï¼Œåœ¨èƒŒæ™¯æ˜¯é›ªæ™¯ï¼ˆä¸€ç‰‡ç™½è‰²ï¼‰ï¼Œä¸”äººçš„åˆ†è¾¨ç‡ä¸é«˜æ—¶æœ‰äº›ä¼ªå½±ã€‚ï¼ˆshijinsai.mp4è¿™ä¸ªè§†é¢‘ï¼Œè½åœ°åæ»‘è¡Œé‚£æ®µæ’å¸§æ—¶ä¼šå‡ºç°ï¼‰ã€‚ ä½†å¯¹äºäººåƒç´ å æ¯”æ¯”è¾ƒå¤šçš„ï¼Œå¦‚é¡¹ç›®ä¸­huaxue.mp4è§†é¢‘å¥½åƒå°±ä¸å¤ªæ˜æ˜¾ã€‚è¿™å¯èƒ½ä¸è®­ç»ƒæ—¶çš„èƒŒæ™¯å›¾é›ªæ™¯è¾ƒå°‘æœ‰å…³ã€‚

## 5.2 ç‰ˆæƒ
ç‰¹æ­¤å£°æ˜ï¼Œé¡¹ç›®ä¸­æ‰€æœ‰è§†é¢‘ç‰ˆæƒå‡å±åŸä½œè€…ï¼ˆshijinsai.mp4=>å¤®è§†æ–°é—»Bç«™ã€huaxue.mp4=>æŠ–éŸ³åŸä½œè€…ï¼‰ï¼Œæ­¤å¤„åªä¸ºå±•ç¤ºæŠ€æœ¯å±•ç¤ºã€‚

PSï¼šaistudioé¡¹ç›®ï¼šhttps://aistudio.baidu.com/aistudio/projectdetail/2074969 ï¼ˆç»™äºˆéœ€è¦ç™½å«–ç®—åŠ›è¿è¡Œçš„åŒå­¦ï¼Œå¯ä»¥å…è´¹ç”¨V100è·‘ï¼Œå°½ç®¡æ˜¯V100ä¹Ÿè¿˜æ˜¯è¦äº›æ—¶é—´çš„ï¼‰
